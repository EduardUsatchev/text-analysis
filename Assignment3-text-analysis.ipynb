{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Eduard Usatchev\n",
      "ID: 205980709\n",
      "mail:eduard.usatchev@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# Details Student 1:\n",
    "print(\"Name: Eduard Usatchev\")\n",
    "print(\"ID: 205980709\")\n",
    "print(\"mail:eduard.usatchev@gmail.com\")\n",
    "\n",
    "# Details Student 2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3452284157.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    get_ipython().system('pip install wn')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    " !pip install wn\n",
    " !python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    " import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    " !pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    " import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(8)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for each model we try:\n",
    "params = {'lr': {'C': [0.01, 0.1, 1, 10, 100,200], 'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                'class_weight':['balanced',None],'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                 'multi_class':['auto', 'ovr', 'multinomial']},\n",
    "          'knn': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'],\n",
    "                  'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "          'cart': {'max_depth': [3, 5, 7], 'criterion': ['gini', 'entropy']\n",
    "                   ,'splitter':[\"best\", \"random\"],'max_features':[None,\"auto\", \"sqrt\", \"log2\"],\n",
    "                    'class_weight':[None,\"balanced\", \"balanced_subsample\"],\n",
    "                   'random_state':[0,42,None]},\n",
    "          'svm': {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf','poly','sigmoid',],\n",
    "                  'random_state':[0,42,None],'gamma':['scale', 'auto'],'class_weight':['balanced',None]\n",
    "                  ,'decision_function_shape':['ovo', 'ovr']},\n",
    "          'LinearSVC': {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'dual': [False,True],\n",
    "                        'loss':['hinge', 'squared_hinge'],'multi_class':['ovr', 'crammer_singer'],\n",
    "                         'class_weight':['balanced',None],'random_state':[0,42,None]},\n",
    "          'MLPClassifier': {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "                            'activation': ['tanh', 'relu','identity', 'logistic'],\n",
    "                            'solver': ['sgd', 'adam','lbfgs'],'random_state':[0,42,None],\n",
    "                            'alpha': [0.0001, 0.05],\n",
    "                            'learning_rate': ['constant','adaptive','invscaling']},\n",
    "          'Perceptron': {'alpha': [0.0001, 0.05], 'penalty': [None, 'l2', 'l1', 'elasticnet']\n",
    "                        ,'random_state':[0,42,None],'class_weight':['balanced',None],\n",
    "                         'early_stopping':[False,True],'shuffle':[False,True]},\n",
    "          'SGDClassifier': {'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron',\n",
    "                                     'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                            'alpha': [0.0001, 0.05],\n",
    "                            'shuffle':[False,True],'early_stopping':[False,True]},\n",
    "           'MultinomialNB':{'alpha':[1,0.1,0.01,0.001,0.0001,0.00001],'fit_prior':[True,False]}}\n",
    "\n",
    "# List of models we try on our data\n",
    "models_list = {'lr': LogisticRegression(),\n",
    "            'knn': KNeighborsClassifier(),\n",
    "            'cart': DecisionTreeClassifier(),\n",
    "            'svm': SVC(),\n",
    "            'LinearSVC':LinearSVC(),\n",
    "            'MLPClassifier':MLPClassifier(),\n",
    "            'Perceptron':Perceptron(),\n",
    "            'SGDClassifier':SGDClassifier(),\n",
    "            'MultinomialNB':MultinomialNB()}\n",
    "\n",
    "# Function that uses the hebrew_tokenizer to tokenize the text\n",
    "def tokenize_text(text):\n",
    "    tokens = ht.tokenize(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing which vectorizer to uze:\n",
    "vectorizer = 'TfidfVectorizer'\n",
    "#vectorizer = 'CountVectorizer'\n",
    "\n",
    "train_file_name = 'annotated_corpus_for_train.csv'\n",
    "df = pd.read_csv(train_file_name, index_col=None, encoding='utf-8') \n",
    "\n",
    "# Removing all of the numbers,punctuations from the train set\n",
    "r = re.compile(r'[^\\w\\s]')\n",
    "df['story'] = [r.sub('',s) for s in df['story'].tolist()]\n",
    "r = re.compile(r'\\d+')\n",
    "df['story'] = [r.sub('',s) for s in df['story'].tolist()]\n",
    "r = re.compile(r'\\s+')\n",
    "df['story'] = df['story'].str.strip()\n",
    "\n",
    "# Spliting the train set into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['story'], df['gender'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Vectorize the text data using the vectorizer we chose above  \n",
    "if vectorizer == 'TfidfVectorizer':\n",
    "    vectorizer = TfidfVectorizer(min_df= 5 ,ngram_range= (1,1))\n",
    "    \n",
    "if vectorizer == 'CountVectorizer':\n",
    "    vectorizer = CountVectorizer(min_df= 5)\n",
    "        \n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# Perform feature selection using mutual information\n",
    "selector = SelectKBest(mutual_info_classif, k=1000) \n",
    "selector.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Apply feature selection to the vectorized data\n",
    "X_train_selected = selector.transform(X_train_vectorized)\n",
    "X_test_selected = selector.transform(X_test_vectorized)\n",
    "\n",
    "# Scaling the data by using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "    \n",
    "X_train_scaled = scaler.fit_transform(X_train_selected.toarray())\n",
    "X_test_scaled = scaler.transform(X_test_selected.toarray())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best parameters from each model by using GridSearchCV\n",
    "best_params = {}\n",
    "for name, model in models_list.items():\n",
    "    print(name)\n",
    "    clf = GridSearchCV(model, params[name], cv=5, n_jobs=-1)\n",
    "    clf.fit(X_train_selected, y_train)\n",
    "    best_params[name] = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dictionary that have all the models we want to try and there best parameters.\n",
    "models = dict()\n",
    "models['lr'] = LogisticRegression(**best_params['lr'])\n",
    "models['knn'] = KNeighborsClassifier(**best_params['knn'])\n",
    "models['cart'] = DecisionTreeClassifier(**best_params['cart'])\n",
    "models['svm'] = SVC(**best_params['svm'])\n",
    "models['LinearSVC'] = LinearSVC(**best_params['LinearSVC'])\n",
    "models['MLPClassifier'] = MLPClassifier(**best_params['MLPClassifier'])\n",
    "models['Perceptron'] = Perceptron(**best_params['Perceptron'])\n",
    "models['SGDClassifier'] = SGDClassifier(**best_params['SGDClassifier'])\n",
    "models['MultinomialNB'] = MultinomialNB(**best_params['MultinomialNB'])\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models\n",
    "# I Learned about the stacking model from here: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/#\n",
    "level0 = []\n",
    "level0.append(('lr_bagging', BaggingClassifier(base_estimator=LogisticRegression(**best_params['lr']), n_estimators=100, max_samples=0.8, oob_score=False)))\n",
    "level0.append(('knn_bagging', BaggingClassifier(base_estimator=KNeighborsClassifier(**best_params['knn']), n_estimators=100, max_samples=0.8, oob_score=False)))\n",
    "level0.append(('cart_bagging', BaggingClassifier(base_estimator=DecisionTreeClassifier(**best_params['cart']), n_estimators=100, max_samples=0.8, oob_score=False)))\n",
    "level0.append(('svm_bagging', BaggingClassifier(base_estimator=SVC(**best_params['svm']), n_estimators=100, max_samples=0.8, oob_score=False)))\n",
    "level0.append(('LinearSVC_bagging', BaggingClassifier(base_estimator=LinearSVC(**best_params['LinearSVC']), n_estimators=100, max_samples=0.8, oob_score=False)))\n",
    "level0.append(('SGDClassifier_bagging', BaggingClassifier(base_estimator=SGDClassifier(**best_params['SGDClassifier']), n_estimators=100, max_samples=0.8, oob_score=False)))\n",
    "level0.append(('MLPClassifier', MLPClassifier(**best_params['MLPClassifier'])))\n",
    "level0.append(('Perceptron', Perceptron(**best_params['Perceptron'])))\n",
    "#level0.append(('MultinomialNB',BaggingClassifier(base_estimator=MultinomialNB(**best_params['MultinomialNB']), n_estimators=100, max_samples=0.8, oob_score=False) ))\n",
    "#level0.append(('MultinomialNB',MultinomialNB(**best_params['MultinomialNB'])))\n",
    "\n",
    "level1 = LogisticRegression(**best_params['lr'])\n",
    "\n",
    "models['stacking'] = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = []\n",
    "\n",
    "# Evaluate the models and store the results\n",
    "results, names = list(), list()\n",
    "y_predict = list()\n",
    "score = {}\n",
    "for name, model in models.items():\n",
    "    model_train = model.fit(X_train_selected , y_train)\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    scores = cross_val_score(model_train, X_test_selected, y_test, scoring='accuracy', cv=cv, n_jobs=-1,error_score='raise')\n",
    "    y_pred = model_train.predict(X_test_selected)\n",
    "    print(model_train)\n",
    "    \n",
    "    f1_male = f1_score(y_test, y_pred, pos_label='m')\n",
    "    f1_female = f1_score(y_test, y_pred, pos_label='f')\n",
    "    average_f1=(f1_male + f1_female)/2\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    scores =  {'Accuracy': {'mean': mean(scores),'std': std(scores)},\n",
    "            'F1 Score (male)': f1_male,\n",
    "            'F1 Score (female)': f1_female,\n",
    "            'Confusion Matrix': conf_mat,\n",
    "            'scores':scores ,\n",
    "            'y_pred':y_pred,\n",
    "            'average_f1':average_f1,\n",
    "            'model':model_train}\n",
    "    \n",
    "    \n",
    "    results.append(scores['scores'])\n",
    "    names.append(name)\n",
    "    score[name] = scores\n",
    "    y_predict.append(scores['y_pred'])\n",
    "    print('%s Accuracy: %.3f (%.3f)' % (name, scores['Accuracy']['mean'], scores['Accuracy']['std']))\n",
    "    print('F1 Score female: %.3f' % (scores['F1 Score (female)']))\n",
    "    print('F1 Score male: %.3f' % (scores['F1 Score (male)']))\n",
    "    print('>F1 Score average_f1: %.3f\\n\\n\\n' % (scores['average_f1']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model performance for comparison\n",
    "pyplot.figure(figsize=(11,5))\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all of the numbers,punctuations from the test set\n",
    "r = re.compile(r'[^\\w\\s]')\n",
    "df_test['story'] = [r.sub('',s) for s in df_test['story'].tolist()]\n",
    "r = re.compile(r'\\d+')\n",
    "df_test['story'] = [r.sub('',s) for s in df_test['story'].tolist()]\n",
    "r = re.compile(r'\\s+')\n",
    "df_test['story'] = df_test['story'].str.strip()\n",
    "\n",
    "# Vectorize the text data using the vectorizer we chose above \n",
    "if vectorizer == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(min_df= 5 ,ngram_range= (1,1))\n",
    "    \n",
    "if vectorizer == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(min_df= 5)\n",
    "\n",
    "X_test = df['story']\n",
    "X_test_vect = vectorizer.fit_transform(X_test)\n",
    "\n",
    "# Perform feature selection using mutual information\n",
    "selector = SelectKBest(mutual_info_classif, k=1000)\n",
    "X_test_selected = selector.fit_transform(X_test_vect, np.zeros(X_test_vect.shape[0]))\n",
    "\n",
    "# Scaling the data by using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(X_test_selected.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_dict = {}\n",
    "for mod in score:\n",
    "    y_pred = score[mod]['model'].predict(X_test_scaled)\n",
    "    df_prediction = pd.DataFrame({'story': X_test, 'predicted gender': y_pred})\n",
    "    print(f\"<Model: {mod}>\")\n",
    "    print(df_prediction['predicted gender'].value_counts())\n",
    "    print(\"\\n\")\n",
    "    df_predict_dict[mod] = df_prediction\n",
    "\n",
    "\n",
    "df_predicted = df_predict_dict['stacking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
